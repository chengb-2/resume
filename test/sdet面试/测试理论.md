### 理论

<details><summary>测试分类</summary><blockquote>

<details><summary>白盒测试 - 单元测试，逻辑驱动测试</summary><blockquote>

**测试对象:** 基于被测试程序的源代码

不仅关注输入输出，同时关注内部逻辑
   
<details>
<summary>穷举路径测试</summary><blockquote>
<p>
       
1. 不能查出程序违反了设计规范，即程序本身是个错误的程序。
2. 不能查出程序中因遗漏路径而出错。
3. 可能发现不了一些与数据相关的错误。
       
</p>
</details>
   
白盒测试能有效地测试程序内部结构，黑盒测试可以更好地站在用户的角度进行测试

<details>
<summary>测试方法</summary><blockquote>
<p>

1. 语句覆盖（Statement Coverage）：测试用例能够覆盖软件中的每个语句，确保每个语句都至少被执行一次。
2. 分支覆盖（Branch Coverage）：测试用例能够覆盖每个条件语句的每个分支，包括真和假的分支。
3. 路径覆盖（Path Coverage）：测试用例能够覆盖软件中的每个可能的执行路径，包括循环和递归。
4. 条件覆盖（Condition Coverage）：测试用例能够覆盖软件中的每个条件，包括真和假的条件。
5. 判定覆盖（Decision Coverage）：测试用例能够覆盖每个返回布尔值的条件语句的真和假的两种情况。
6. 决策覆盖（Logical Coverage）：测试用例能够覆盖每个包含条件语句的决策点，包括简单决策和复合决策。

</p>
</details>
   
<details>
<summary>举例</summary><blockquote>
    
```Java
public class Example {
     public static int getOutput(int a, int b) {
        int output = 0;
        if (a == 0) {
              output += 1;
        }
        if (b > 5) {
              output += 2;
        }
        return output;
     }
}
```
   
```Java
public class ExampleTest {
@Test
public void testGetOutputStatementCoverage() {
    int result = Example.getOutput(0, 6);
    assert result == 3 : "Failed statement coverage test with input (0, 6)";
}

@Test
public void testGetOutputDecisionCoverage() {
    int result1 = Example.getOutput(1, 6);
    assert result1 == 0 : "Failed decision coverage test with input (1, 6)";
    int result2 = Example.getOutput(0, 4);
    assert result2 == 1 : "Failed decision coverage test with input (0, 4)";
    int result3 = Example.getOutput(0, 6);
    assert result3 == 3 : "Failed decision coverage test with input (0, 6)";
}

@Test
public void testGetOutputConditionCoverage() {
    int result1 = Example.getOutput(1, 6);
    assert result1 == 0 : "Failed condition coverage test with input (1, 6)";
    int result2 = Example.getOutput(0, 4);
    assert result2 == 1 : "Failed condition coverage test with input (0, 4)";
    int result3 = Example.getOutput(0, 6);
    assert result3 == 3 : "Failed condition coverage test with input (0, 6)";
    int result4 = Example.getOutput(1, 5);
    assert result4 == 0 : "Failed condition coverage test with input (1, 5)";
  }
}
```
</details>
</details>

<details><summary>灰盒测试 - 集成测试</summary><blockquote>
检测单个模块组成在一起是否有问题。
</details>
    
<details><summary>黑盒测试 - 系统测试，数据驱动测试</summary><blockquote>

只关注输入输出。不关注实现，只要结果正确即可。

需要测试合法输入，不合法但可能的输入。

更接近用户使用的测试，所以关于用户使用流程、易用性等方面并不是白盒测试可以测试到的，也就是如果白盒测试没问题后，并不能保证程序的易用性、界面显示、业务流程等内容就一定没有错误

测试结果的覆盖度不容易度量，其测试的潜在风险比较高。
   
<details>
<summary>方法</summary><blockquote>
<p>

1. 等价类划分法（Equivalence Partitioning）：将所有可能的输入划分为若干等价类，每个等价类代表一组具有相同特征的输入数据，然后从每个等价类中选择一个代表性的测试用例进行测试。例如，对于一个接受年龄输入的程序，我们可以将年龄划分为小于18岁、18-60岁和大于60岁三个等价类，然后分别选择一个测试用例来测试。
2. 边界值分析法（Boundary Value Analysis）：针对输入数据的边界值进行测试。通常来说，程序在边界处容易出现问题。例如，对于一个接受数字输入的程序，我们需要测试最小值、最大值和一些接近最小值和最大值的输入。
3. 因果图法（Cause-Effect Graph）：将程序中的输入和输出关系表示为一个因果图，然后通过对因果图进行分析，设计测试用例来测试程序的输入和输出关系。因果图可以帮助测试人员发现可能存在的逻辑错误。
4. 错误推断法（Error Guessing）：通过猜测程序可能存在的错误或缺陷，然后设计测试用例来验证这些猜测。例如，假设程序在处理一些特定输入时容易出现问题，我们可以设计一组测试用例来验证这种猜测。
5. 随机测试法（Random Testing）：使用随机生成的数据来测试程序。随机测试可以帮助测试人员发现一些未考虑到的输入情况和边界情况。 

</p>
</details>
</details>
    
</details>
    
<details>
<summary>测试流程</summary>
<ol>    
    <li>需求分析阶段：测试人员需要仔细阅读软件需求文档，了解软件系统的功能、性能和安全等方面的要求。测试人员也需要与开发人员和需求方沟通，澄清需求和确认测试计划。</li>
    <li>测试计划阶段：测试人员需要制定测试计划和测试用例。测试计划包括测试范围、测试目标、测试策略、测试资源和时间计划等方面的内容。测试用例则是针对不同的功能模块和场景，制定的一系列测试步骤和预期结果。</li>
    <li>测试执行阶段：测试人员根据测试计划和测试用例，执行各种类型的测试活动，例如功能测试、性能测试、安全测试、用户体验测试等。测试人员需要记录测试结果，并及时提交Bug报告。</li>
    <li>bug管理阶段：测试人员需要对测试结果进行分析和整理，记录bug并进行分类和优先级划分。测试人员还需要与开发人员和需求方沟通，确认bug的修复和验证方案。</li>
    <li>撰写bug文档：测试人员需要撰写测试报告，总结测试结果和缺陷情况。测试报告包括测试概述、测试结果、缺陷统计和测试建议等方面的内容。测试报告需要提交给相关的利益相关者，例如开发人员、需求方和项目经理等。</li>
    <li>测试闭环阶段：测试人员需要对修复后的软件进行验证和确认，确保缺陷已经被修复并且没有引入新的缺陷。测试人员还需要撰写测试总结，为下一轮测试活动做好准备</li>       
</ol>
</details>


<details>
<summary>bug文档写什么</summary>
<ol>   
    <li>bug的描述：对bug详细的描述，包括bug的出现条件、复现步骤、预期结果和实际结果等。</li>
    <li>bug的分类：对bug进行分类，例如功能性问题、性能问题、安全问题等。</li>
    <li>bug的优先级：对bug进行优先级划分，例如高优先级、中优先级、低优先级等。优先级的划分通常基于缺陷的严重程度、影响范围和修复难度等因素进行评估。</li>
    <li>bug的状态：记录bug的当前状态，例如已发现、已确认、已修复、已验证等。测试人员和开发人员可以通过bug状态的更新，实时了解bug的处理情况和进展。</li>
    <li>缺陷的附件：如果需要，可以添加一些附件来支持bug的描述和复现，例如截图、录屏等。</li>
</ol>
</details>


<details>
<summary>接口测试</summary>
<ol>
    <li>接口正常使用</li>
    <li>参数必填/选填，参数边界值，类型异常，null，参数名错误，个数+1/-1</li>
    <li>参数组合验证</li>
    <li>安全性：认证/授权，SQL注入，敏感信息</li>
    <li>性能 - 没测</li>       
</ol>
</details>


<details>
<summary>自动化测试工具</summary>

Selenium - web, Appium - app,  Robotium - Android

</details>
  
<details>
<summary>JUnit & JaCoCo</summary>

Jacoco计算覆盖率公式：
      
      Code Coverage Percentage = (Number of lines of code executed by a testing algorithm/Total number of lines of code in a system component) * 100
      
</details>
    
- 抓包工具charles
    
    [抓包神器-Charles的使用指南 - 开发者头条](https://toutiao.io/posts/fem0sp/preview)

<details>
<summary>server测试</summary>
第一种：直接对WEB或者APP的服务端进行测试

后台测试接口一般提供给iOS/Android端，需要跟不同端的测试人员协调测试进度、测试环境等注意事项

性能测试：编写脚本进行压力测试，看看后端服务能不能撑住大流量。细分起来会有各种类型，比如负载测试、压力测试、配置测试、甚至还有线上压测、容量规划等。最常规的性能测试，一般是先规定一个系统需要承受的压力，比如说，某一个系统，1个小时之内会有1W单的单子，那基于这个需求我们分析服务器后端需要承受的压力，分析出来以后，就写性能测试脚本，然后逐渐增加压测的力度，直到超过这个预定的压力。通常在这个测试过程中会发现各种问题，比如数据库索引没有建、线程池太小、系统异常等。需要解决了之后再加大压力测试。也是用Grinder／JMeter等工具来进行性能测试，不过难的不是这些工具的使用，而是发现问题以后的定位。

第二种：对更后端的数据库、缓存系统、中间件、文件系统等进行测试。

异常测试：模拟各种异常情况，比如硬件异常－机器挂掉的情况下能否启动备机、硬盘挂掉的情况下是否会丢失数据；网络异常－网络忽然断掉、或者网络流量变小的情况；系统异常－操作系统忽然挂掉的情况。这些极端的情况出现的时候，我们需要验证数据有没有丢、能不能尽快启动备机对外提供服务、系统状态有没有异常等。我们会采用各种方式或者工具来模拟这些异常，比如用TrafficControl工具来控制网络流量。

稳定性测试，模拟系统在7*24的运行下会不会出问题，一般会用接口测试或者性能测试用例不断地跑，在运行期间，我们会模拟各种情况，比如说负载的变化、系统的各种干扰等。可以用ChaosMonkey等工具来进行这类测试。
</details>


<details><summary>测试分类</summary><blockquote>
   
<details>
<summary>unit test</summary>
Unit tests always take results from a single unit, such as a function call.
</details>

<details>
<summary>integration test</summary>
Integration tests may aggregate results from various parts and sources.
</details>

<details>
<summary>exception test异常测试</summary>
It is necessary to simulate internal system failures to test the effectiveness of the system's disaster recovery plan.
</details>

<details>
<summary>performance test性能测试</summary>
Performance testing is the practice of evaluating how a system performs in terms of responsiveness and stability under a particular workload.
</details>

<details>
<summary>regression test回归测试</summary>
Regression testing is re-running functional and non-functional tests to ensure that previously developed and tested software still performs as expected after a change.
</details>

<details>
<summary>A/B testing</summary>
A/B testing compares the performance of two versions of content to see which one appeals more to visitors/viewers.
</details>
</details>
